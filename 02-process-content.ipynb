{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153d560d-a721-426e-9976-913d8bae17cf",
   "metadata": {},
   "source": [
    "# Process Content\n",
    "Purpose is to take content stored in blob storage and process it into a separate container.\n",
    "The new container will consist of json files that have all the data needed to push into Azure AI Search.\n",
    "This json data is stored for potential BCDR and Geo-replication needs so that content does not need to be reprocessed.\n",
    "\n",
    "## Required for this step\n",
    "- Azure Blob Storage (with content)\n",
    "- Azure OpenAI (completions model and Ada-002 embeddings)\n",
    "- Azure Document Intelligence\n",
    "\n",
    "## Important\n",
    "- This demo was done on Ubuntu which uses LibreOffice to do conversion of documents to PDF for a standard processing format\n",
    "- PDFKit is used for converting html to PDF - this may need: sudo apt-get install wkhtmltopdf  \r\n",
    "- If using Linux run: sudo apt-get install libreoffice\n",
    "  - eg: !lowriter --convert-to pdf marketbulletin021505.doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c399b70-9d9b-4a12-8f76-437b669cc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import required libraries  \n",
    "import os  \n",
    "import base64\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "from requests import get, post\n",
    "import json\n",
    "import time\n",
    "import copy  \n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, generate_blob_sas, BlobSasPermissions  \n",
    "from datetime import datetime, timedelta  \n",
    "import pdfkit\n",
    "from langchain.text_splitter import TokenTextSplitter, MarkdownHeaderTextSplitter\n",
    "import pickle\n",
    "from openai import AzureOpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed974b8-42bc-43fa-87ce-ecee61abb09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp Dir: /aci/data/data/customers/financial-docs/tmp\n",
      "Pickle Dir: /aci/data/data/customers/financial-docs/pkl\n",
      "JSON Dir: /aci/data/data/customers/financial-docs/json\n"
     ]
    }
   ],
   "source": [
    "#Load the configuration details for the Cognitive Search Service and Azure OpenAI Instance\n",
    "#Credentials should be secured using a more secure method such as Azure KeyVault\n",
    "config = json.load(open(\"config.json\"))\n",
    "\n",
    "# Azure Blob Storage Config\n",
    "blob_service_name = config[\"blob_service_name\"]\n",
    "blob_container = config[\"blob_container\"]\n",
    "blob_key = config[\"blob_key\"]\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=\" + blob_service_name + \";AccountKey=\" + blob_key + \";EndpointSuffix=core.windows.net\"  \n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)  \n",
    "container_client = blob_service_client.get_container_client(blob_container) \n",
    "\n",
    "#Azure OpenAI\n",
    "api_base = config[\"openai_api_base\"]\n",
    "api_key = config[\"openai_api_key\"]\n",
    "openai_api_version = config[\"openai_api_version\"]\n",
    "embeddings_model = config[\"openai_embedding_model\"]\n",
    "gpt_model = config[\"openai_gpt_model\"] \n",
    "\n",
    "# Doc Intelligence Config\n",
    "di_endpoint = config[\"doc_intelligence_endpoint\"]\n",
    "di_apim_key = config[\"doc_intelligence_apim_key\"]\n",
    "di_headers = {\n",
    "    'Content-Type': 'application/pdf',\n",
    "    'Ocp-Apim-Subscription-Key': di_apim_key,\n",
    "}\n",
    "di_post_url = di_endpoint + \"documentintelligence/documentModels/prebuilt-layout:analyze?api-version=2023-10-31-preview&stringIndexType=utf16CodeUnit&outputContentFormat=markdown\"\n",
    "\n",
    "# Set a temp directory for downloading pdf's for processing\n",
    "data_root_dir = config[\"data_root_dir\"]\n",
    "tmp_dir = os.path.join(data_root_dir, \"tmp\")\n",
    "pkl_dir = os.path.join(data_root_dir, \"pkl\")\n",
    "json_dir = os.path.join(data_root_dir, \"json\")\n",
    "\n",
    "# Chunking Config\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=52)  \n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_version=openai_api_version,\n",
    "    azure_endpoint=api_base,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "print ('Temp Dir:', tmp_dir)\n",
    "print ('Pickle Dir:', pkl_dir)\n",
    "print ('JSON Dir:', json_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87aad72a-2f4d-4104-be86-07eb578b916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=embeddings_model\n",
    "    )\n",
    "    return json.loads(response.model_dump_json())[\"data\"][0]['embedding']\n",
    "\n",
    "# Create a title based on a supplied set of text\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_title(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=gpt_model, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Assistant who creates succint titles for content.\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# reset output dir\n",
    "def reset_dir(dir):\n",
    "    processed_path = Path(dir)\n",
    "    if processed_path.exists():\n",
    "        rmtree(processed_path)\n",
    "    processed_path.mkdir(parents=True)\n",
    "\n",
    "# Get all files in dir\n",
    "def get_files_in_dir(in_dir):\n",
    "    return [os.path.join(dp, f) for dp, dn, filenames in os.walk(in_dir) for f in filenames]\n",
    "\n",
    "def base64_encode_string(s):\n",
    "    # encode the string into bytes, then encode it in base64  \n",
    "    encoded = base64.b64encode(s.encode('utf-8'))  \n",
    "    return encoded.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1c898c-ee71-4500-9106-59db5cc90372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_embeddings('test')[:10]\n",
    "# generate_title('The quick brown fox jumped over the lazy dog.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b634015d-5d1f-4248-9733-40c7c4e53c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for downloading and processing\n",
    "reset_dir(tmp_dir)\n",
    "reset_dir(pkl_dir)\n",
    "reset_dir(json_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf678d3-9648-499e-b19a-8dc668512daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MSFT_FY22Q4_10K.docx\n",
      "Downloading MSFT_FY22Q4_10K.docx to /aci/data/data/customers/financial-docs/tmp/MSFT_FY22Q4_10K.docx ...\n",
      "Converting file to PDF format...\n",
      "convert /aci/data/data/customers/financial-docs/tmp/MSFT_FY22Q4_10K.docx -> /aci/data/data/customers/financial-docs/tmp/MSFT_FY22Q4_10K.pdf using filter : writer_pdf_Export\n",
      "/aci/data/data/customers/financial-docs/tmp/MSFT_FY22Q4_10K.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/MSFT_FY22Q4_10K.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/3da8d9ec-fa6d-4a11-9238-b2954befe4aa?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '149', 'apim-request-id': '3da8d9ec-fa6d-4a11-9238-b2954befe4aa', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:53:16 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/3da8d9ec-fa6d-4a11-9238-b2954befe4aa?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing NVIDIA-10Q.pdf\n",
      "Downloading NVIDIA-10Q.pdf to /aci/data/data/customers/financial-docs/tmp/NVIDIA-10Q.pdf ...\n",
      "/aci/data/data/customers/financial-docs/tmp/NVIDIA-10Q.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/NVIDIA-10Q.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/73913f1c-a904-4a36-9fa0-38a8ed7290e2?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '102', 'apim-request-id': '73913f1c-a904-4a36-9fa0-38a8ed7290e2', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:53:37 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/73913f1c-a904-4a36-9fa0-38a8ed7290e2?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing msft-2022_Annual_Report.docx\n",
      "Downloading msft-2022_Annual_Report.docx to /aci/data/data/customers/financial-docs/tmp/msft-2022_Annual_Report.docx ...\n",
      "Converting file to PDF format...\n",
      "convert /aci/data/data/customers/financial-docs/tmp/msft-2022_Annual_Report.docx -> /aci/data/data/customers/financial-docs/tmp/msft-2022_Annual_Report.pdf using filter : writer_pdf_Export\n",
      "/aci/data/data/customers/financial-docs/tmp/msft-2022_Annual_Report.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/msft-2022_Annual_Report.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/15475279-6d3e-4c8d-adb3-b82e4e6dfd94?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '107', 'apim-request-id': '15475279-6d3e-4c8d-adb3-b82e4e6dfd94', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:53:58 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/15475279-6d3e-4c8d-adb3-b82e4e6dfd94?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing msft-2022_Shareholder_Letter.docx\n",
      "Downloading msft-2022_Shareholder_Letter.docx to /aci/data/data/customers/financial-docs/tmp/msft-2022_Shareholder_Letter.docx ...\n",
      "Converting file to PDF format...\n",
      "convert /aci/data/data/customers/financial-docs/tmp/msft-2022_Shareholder_Letter.docx -> /aci/data/data/customers/financial-docs/tmp/msft-2022_Shareholder_Letter.pdf using filter : writer_pdf_Export\n",
      "/aci/data/data/customers/financial-docs/tmp/msft-2022_Shareholder_Letter.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/msft-2022_Shareholder_Letter.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/a9ba7d80-4d1f-443a-9eee-8d3659f03b81?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '53', 'apim-request-id': 'a9ba7d80-4d1f-443a-9eee-8d3659f03b81', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:54:17 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/a9ba7d80-4d1f-443a-9eee-8d3659f03b81?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing nvda-2023-Annual-Report-1.pdf\n",
      "Downloading nvda-2023-Annual-Report-1.pdf to /aci/data/data/customers/financial-docs/tmp/nvda-2023-Annual-Report-1.pdf ...\n",
      "/aci/data/data/customers/financial-docs/tmp/nvda-2023-Annual-Report-1.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/nvda-2023-Annual-Report-1.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/4c476589-f2e4-4935-ae15-ad00e69a70aa?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '1281', 'apim-request-id': '4c476589-f2e4-4935-ae15-ad00e69a70aa', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:54:27 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/4c476589-f2e4-4935-ae15-ad00e69a70aa?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis failed:\n",
      "\n",
      "Processing nvda-Q3FY24-CFO-Commentary.pdf\n",
      "Downloading nvda-Q3FY24-CFO-Commentary.pdf to /aci/data/data/customers/financial-docs/tmp/nvda-Q3FY24-CFO-Commentary.pdf ...\n",
      "/aci/data/data/customers/financial-docs/tmp/nvda-Q3FY24-CFO-Commentary.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/nvda-Q3FY24-CFO-Commentary.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/28e5105d-1fc7-4b22-b19d-9bffd24fb3b8?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '93', 'apim-request-id': '28e5105d-1fc7-4b22-b19d-9bffd24fb3b8', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:55:44 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/28e5105d-1fc7-4b22-b19d-9bffd24fb3b8?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing orcl-2q24-pressrelease-December-final.pdf\n",
      "Downloading orcl-2q24-pressrelease-December-final.pdf to /aci/data/data/customers/financial-docs/tmp/orcl-2q24-pressrelease-December-final.pdf ...\n",
      "/aci/data/data/customers/financial-docs/tmp/orcl-2q24-pressrelease-December-final.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/orcl-2q24-pressrelease-December-final.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/96d7bd5a-2ca1-4861-8913-1f3ae29ed66c?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '109', 'apim-request-id': '96d7bd5a-2ca1-4861-8913-1f3ae29ed66c', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:55:49 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/96d7bd5a-2ca1-4861-8913-1f3ae29ed66c?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing orcl-Q224_Form8K_Exhibit99-1_Earnings_Release_Tables_Final.pdf\n",
      "Downloading orcl-Q224_Form8K_Exhibit99-1_Earnings_Release_Tables_Final.pdf to /aci/data/data/customers/financial-docs/tmp/orcl-Q224_Form8K_Exhibit99-1_Earnings_Release_Tables_Final.pdf ...\n",
      "/aci/data/data/customers/financial-docs/tmp/orcl-Q224_Form8K_Exhibit99-1_Earnings_Release_Tables_Final.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/orcl-Q224_Form8K_Exhibit99-1_Earnings_Release_Tables_Final.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/1701ba45-04db-4e24-a8eb-92c55ff530d7?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '60', 'apim-request-id': '1701ba45-04db-4e24-a8eb-92c55ff530d7', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:55:57 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/1701ba45-04db-4e24-a8eb-92c55ff530d7?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n",
      "Processing orcl-f20d8dea-697e-464e-b775-b0e33d1db211.pdf\n",
      "Downloading orcl-f20d8dea-697e-464e-b775-b0e33d1db211.pdf to /aci/data/data/customers/financial-docs/tmp/orcl-f20d8dea-697e-464e-b775-b0e33d1db211.pdf ...\n",
      "/aci/data/data/customers/financial-docs/tmp/orcl-f20d8dea-697e-464e-b775-b0e33d1db211.pdf\n",
      "Processing /aci/data/data/customers/financial-docs/tmp/orcl-f20d8dea-697e-464e-b775-b0e33d1db211.pdf\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/a2adeaaf-dfad-43ff-a7a5-71827f72c5a1?api-version=2023-10-31-preview', 'x-envoy-upstream-service-time': '104', 'apim-request-id': 'a2adeaaf-dfad-43ff-a7a5-71827f72c5a1', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'West US 2', 'Date': 'Fri, 01 Mar 2024 16:56:04 GMT'}\n",
      "https://vikurpad-collab.cognitiveservices.azure.com/documentintelligence/documentModels/prebuilt-layout/analyzeResults/a2adeaaf-dfad-43ff-a7a5-71827f72c5a1?api-version=2023-10-31-preview\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Waiting to complete processing...\n",
      "Layout Analysis succeeded:\n",
      "\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Download and process blobs\n",
    "blob_list = container_client.list_blobs()  \n",
    "\n",
    "# Iterate through each blob  \n",
    "documents = []\n",
    "for blob in blob_list:  \n",
    "    file_type = os.path.splitext(blob.name)[1].lower()\n",
    "    pkl_file = os.path.join(pkl_dir, os.path.basename(blob.name) + '.pkl')\n",
    "\n",
    "\n",
    "    if os.path.exists(pkl_file) == False:\n",
    "        if (file_type == \".pdf\") or (file_type == \".docx\") or (file_type == \".doc\") or (file_type == \".html\") or (file_type == \".htm\"):\n",
    "            print ('Processing', blob.name)\n",
    "            # Create a blob client for the blob  \n",
    "            blob_client = blob_service_client.get_blob_client(blob_container, blob.name)  \n",
    "            local_file = os.path.join(tmp_dir, blob.name)\n",
    "\n",
    "            # Download file locally\n",
    "            print ('Downloading', blob.name, 'to', local_file, '...')\n",
    "            with open(local_file, \"wb\") as download_file:  \n",
    "                download_file.write(blob_client.download_blob().readall())  \n",
    "    \n",
    "            pdf_file = local_file\n",
    "            # Conver file to PDF format (if it is not already PDF)\n",
    "            if file_type != \".pdf\":\n",
    "                print ('Converting file to PDF format...')\n",
    "                pdf_file = os.path.join(tmp_dir, blob.name.split('.')[:len(blob.name.split('.'))-1][0] + '.pdf')\n",
    "                if file_type == \".html\":\n",
    "                    pdfkit.from_file(local_file, pdf_file)\n",
    "                else:\n",
    "                    os.system(\"lowriter --convert-to pdf \" + local_file + \" --outdir \" + tmp_dir) \n",
    "    \n",
    "            print (pdf_file)\n",
    "    \n",
    "            print ('Processing', pdf_file)\n",
    "            with open(pdf_file, \"rb\") as f:\n",
    "                data_bytes = f.read()\n",
    "    \n",
    "    \n",
    "            resp = post(url = di_post_url, data = data_bytes, headers = di_headers)\n",
    "            if resp.status_code != 202:\n",
    "                print(\"POST analyze failed:\\n%s\" % resp.text)\n",
    "                quit()\n",
    "            print(\"POST analyze succeeded:\\n%s\" % resp.headers)\n",
    "            get_url = resp.headers[\"operation-location\"]\n",
    "            \n",
    "            if resp.status_code == 202:\n",
    "                get_url = resp.headers['Operation-Location']\n",
    "                print (get_url)\n",
    "            \n",
    "            n_tries = 10\n",
    "            n_try = 0\n",
    "            wait_sec = 2\n",
    "            processing = True\n",
    "            while processing:\n",
    "                try:\n",
    "                    resp = get(url = get_url, headers = {\"Ocp-Apim-Subscription-Key\": di_apim_key})\n",
    "                    resp_json = json.loads(resp.text)\n",
    "                    if resp.status_code != 200:\n",
    "                        # print(\"GET Layout results failed:\\n%s\" % resp_json)\n",
    "                        print(\"GET Layout results failed:\\n\")\n",
    "                        processing = False\n",
    "                    elif resp_json[\"status\"] == \"succeeded\":\n",
    "                        # print(\"Layout Analysis succeeded:\\n%s\" % resp_json)\n",
    "                        print(\"Layout Analysis succeeded:\\n\")\n",
    "                        print(\"--------------------------------\")\n",
    "                        processing = False\n",
    "                    elif resp_json[\"status\"] == \"failed\":\n",
    "                        # print(\"Layout Analysis failed:\\n%s\" % resp_json)\n",
    "                        print(\"Layout Analysis failed:\\n\")\n",
    "                        processing = False\n",
    "                    else:\n",
    "                        # Analysis still running. Wait and retry.\n",
    "                        print ('Waiting to complete processing...')\n",
    "                        time.sleep(wait_sec)\n",
    "                except Exception as e:\n",
    "                    msg = \"GET analyze results failed:\\n%s\" % str(e)\n",
    "                    print(msg)\n",
    "                    processing = False\n",
    "            \n",
    "            # Persist the Doc Int Output for further processing\n",
    "            if 'analyzeResult' in resp_json:\n",
    "                with open(pkl_file, 'wb') as pkl_out:\n",
    "                    pickle.dump(resp_json['analyzeResult'], pkl_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print ('Skipping - Unsupported file type')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed470446-04f0-4c93-8a4c-4f79c0216ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PKL files: 8\n"
     ]
    }
   ],
   "source": [
    "# Get the pkl files for processing of JSON files\n",
    "pkl_files = get_files_in_dir(pkl_dir)\n",
    "total_files = len(pkl_files)\n",
    "print ('Total PKL files:', total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0ddace-6901-44c2-8983-565559d69ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aci/data/data/customers/financial-docs/pkl/msft-2022_Annual_Report.docx.pkl\n",
      "Processing Section: 1 of 185 with 2 chunks...\n",
      "Processing Section: 2 of 185 with 1 chunks...\n",
      "Processing Section: 3 of 185 with 2 chunks...\n",
      "Processing Section: 4 of 185 with 2 chunks...\n",
      "Processing Section: 5 of 185 with 1 chunks...\n",
      "Processing Section: 6 of 185 with 1 chunks...\n",
      "Processing Section: 7 of 185 with 2 chunks...\n",
      "Processing Section: 8 of 185 with 1 chunks...\n",
      "Processing Section: 9 of 185 with 1 chunks...\n",
      "Processing Section: 10 of 185 with 1 chunks...\n",
      "Processing Section: 11 of 185 with 1 chunks...\n",
      "Processing Section: 12 of 185 with 2 chunks...\n",
      "Processing Section: 13 of 185 with 2 chunks...\n",
      "Processing Section: 14 of 185 with 3 chunks...\n",
      "Processing Section: 15 of 185 with 1 chunks...\n",
      "Processing Section: 16 of 185 with 1 chunks...\n",
      "Processing Section: 17 of 185 with 1 chunks...\n",
      "Processing Section: 18 of 185 with 1 chunks...\n",
      "Processing Section: 19 of 185 with 2 chunks...\n",
      "Processing Section: 20 of 185 with 3 chunks...\n",
      "Processing Section: 21 of 185 with 2 chunks...\n",
      "Processing Section: 22 of 185 with 2 chunks...\n",
      "Processing Section: 23 of 185 with 1 chunks...\n",
      "Processing Section: 24 of 185 with 1 chunks...\n",
      "Processing Section: 25 of 185 with 1 chunks...\n",
      "Processing Section: 26 of 185 with 1 chunks...\n",
      "Processing Section: 27 of 185 with 1 chunks...\n",
      "Processing Section: 28 of 185 with 1 chunks...\n",
      "Processing Section: 29 of 185 with 1 chunks...\n",
      "Processing Section: 30 of 185 with 2 chunks...\n",
      "Processing Section: 31 of 185 with 1 chunks...\n",
      "Processing Section: 32 of 185 with 1 chunks...\n",
      "Processing Section: 33 of 185 with 1 chunks...\n",
      "Processing Section: 34 of 185 with 1 chunks...\n",
      "Processing Section: 35 of 185 with 1 chunks...\n",
      "Processing Section: 36 of 185 with 1 chunks...\n",
      "Processing Section: 37 of 185 with 1 chunks...\n",
      "Processing Section: 38 of 185 with 1 chunks...\n",
      "Processing Section: 39 of 185 with 1 chunks...\n",
      "Processing Section: 40 of 185 with 1 chunks...\n",
      "Processing Section: 41 of 185 with 1 chunks...\n",
      "Processing Section: 42 of 185 with 2 chunks...\n",
      "Processing Section: 43 of 185 with 1 chunks...\n",
      "Processing Section: 44 of 185 with 1 chunks...\n",
      "Processing Section: 45 of 185 with 1 chunks...\n",
      "Processing Section: 46 of 185 with 1 chunks...\n",
      "Processing Section: 47 of 185 with 1 chunks...\n",
      "Processing Section: 48 of 185 with 1 chunks...\n",
      "Processing Section: 49 of 185 with 1 chunks...\n",
      "Processing Section: 50 of 185 with 2 chunks...\n",
      "Processing Section: 51 of 185 with 1 chunks...\n",
      "Processing Section: 52 of 185 with 1 chunks...\n",
      "Processing Section: 53 of 185 with 1 chunks...\n",
      "Processing Section: 54 of 185 with 1 chunks...\n",
      "Processing Section: 55 of 185 with 1 chunks...\n",
      "Processing Section: 56 of 185 with 1 chunks...\n",
      "Processing Section: 57 of 185 with 1 chunks...\n",
      "Processing Section: 58 of 185 with 1 chunks...\n",
      "Processing Section: 59 of 185 with 1 chunks...\n",
      "Processing Section: 60 of 185 with 1 chunks...\n",
      "Processing Section: 61 of 185 with 1 chunks...\n",
      "Processing Section: 62 of 185 with 2 chunks...\n",
      "Processing Section: 63 of 185 with 2 chunks...\n",
      "Processing Section: 64 of 185 with 1 chunks...\n",
      "Processing Section: 65 of 185 with 1 chunks...\n",
      "Processing Section: 66 of 185 with 1 chunks...\n",
      "Processing Section: 67 of 185 with 1 chunks...\n",
      "Processing Section: 68 of 185 with 1 chunks...\n",
      "Processing Section: 69 of 185 with 2 chunks...\n",
      "Processing Section: 70 of 185 with 1 chunks...\n",
      "Processing Section: 71 of 185 with 1 chunks...\n",
      "Processing Section: 72 of 185 with 3 chunks...\n",
      "Processing Section: 73 of 185 with 1 chunks...\n",
      "Processing Section: 74 of 185 with 1 chunks...\n",
      "Processing Section: 75 of 185 with 1 chunks...\n",
      "Processing Section: 76 of 185 with 1 chunks...\n",
      "Processing Section: 77 of 185 with 1 chunks...\n",
      "Processing Section: 78 of 185 with 1 chunks...\n",
      "Processing Section: 79 of 185 with 2 chunks...\n",
      "Processing Section: 80 of 185 with 1 chunks...\n",
      "Processing Section: 81 of 185 with 2 chunks...\n",
      "Processing Section: 82 of 185 with 1 chunks...\n",
      "Processing Section: 83 of 185 with 1 chunks...\n",
      "Processing Section: 84 of 185 with 1 chunks...\n",
      "Processing Section: 85 of 185 with 1 chunks...\n",
      "Processing Section: 86 of 185 with 1 chunks...\n",
      "Processing Section: 87 of 185 with 1 chunks...\n",
      "Processing Section: 88 of 185 with 1 chunks...\n",
      "Processing Section: 89 of 185 with 1 chunks...\n",
      "Processing Section: 90 of 185 with 1 chunks...\n",
      "Processing Section: 91 of 185 with 1 chunks...\n",
      "Processing Section: 92 of 185 with 1 chunks...\n",
      "Processing Section: 93 of 185 with 1 chunks...\n",
      "Processing Section: 94 of 185 with 1 chunks...\n",
      "Processing Section: 95 of 185 with 1 chunks...\n",
      "Processing Section: 96 of 185 with 1 chunks...\n",
      "Processing Section: 97 of 185 with 1 chunks...\n",
      "Processing Section: 98 of 185 with 1 chunks...\n",
      "Processing Section: 99 of 185 with 2 chunks...\n",
      "Processing Section: 100 of 185 with 1 chunks...\n",
      "Processing Section: 101 of 185 with 1 chunks...\n",
      "Processing Section: 102 of 185 with 1 chunks...\n",
      "Processing Section: 103 of 185 with 1 chunks...\n",
      "Processing Section: 104 of 185 with 1 chunks...\n",
      "Processing Section: 105 of 185 with 7 chunks...\n",
      "Processing Section: 106 of 185 with 1 chunks...\n",
      "Processing Section: 107 of 185 with 1 chunks...\n",
      "Processing Section: 108 of 185 with 1 chunks...\n",
      "Processing Section: 109 of 185 with 1 chunks...\n",
      "Processing Section: 110 of 185 with 1 chunks...\n",
      "Processing Section: 111 of 185 with 1 chunks...\n",
      "Processing Section: 112 of 185 with 1 chunks...\n",
      "Processing Section: 113 of 185 with 3 chunks...\n",
      "Processing Section: 114 of 185 with 1 chunks...\n",
      "Processing Section: 115 of 185 with 1 chunks...\n",
      "Processing Section: 116 of 185 with 1 chunks...\n",
      "Processing Section: 117 of 185 with 1 chunks...\n",
      "Processing Section: 118 of 185 with 1 chunks...\n",
      "Processing Section: 119 of 185 with 1 chunks...\n",
      "Processing Section: 120 of 185 with 1 chunks...\n",
      "Processing Section: 121 of 185 with 1 chunks...\n",
      "Processing Section: 122 of 185 with 1 chunks...\n",
      "Processing Section: 123 of 185 with 1 chunks...\n",
      "Processing Section: 124 of 185 with 1 chunks...\n",
      "Processing Section: 125 of 185 with 1 chunks...\n",
      "Processing Section: 126 of 185 with 1 chunks...\n",
      "Processing Section: 127 of 185 with 1 chunks...\n",
      "Processing Section: 128 of 185 with 1 chunks...\n",
      "Processing Section: 129 of 185 with 1 chunks...\n",
      "Processing Section: 130 of 185 with 1 chunks...\n",
      "Processing Section: 131 of 185 with 1 chunks...\n",
      "Processing Section: 132 of 185 with 1 chunks...\n",
      "Processing Section: 133 of 185 with 4 chunks...\n",
      "Processing Section: 134 of 185 with 2 chunks...\n",
      "Processing Section: 135 of 185 with 1 chunks...\n",
      "Processing Section: 136 of 185 with 1 chunks...\n",
      "Processing Section: 137 of 185 with 1 chunks...\n",
      "Processing Section: 138 of 185 with 1 chunks...\n",
      "Processing Section: 139 of 185 with 1 chunks...\n",
      "Processing Section: 140 of 185 with 1 chunks...\n",
      "Processing Section: 141 of 185 with 1 chunks...\n",
      "Processing Section: 142 of 185 with 3 chunks...\n",
      "Processing Section: 143 of 185 with 1 chunks...\n",
      "Processing Section: 144 of 185 with 1 chunks...\n",
      "Processing Section: 145 of 185 with 1 chunks...\n",
      "Processing Section: 146 of 185 with 1 chunks...\n",
      "Processing Section: 147 of 185 with 1 chunks...\n",
      "Processing Section: 148 of 185 with 1 chunks...\n",
      "Processing Section: 149 of 185 with 1 chunks...\n",
      "Processing Section: 150 of 185 with 4 chunks...\n",
      "Processing Section: 151 of 185 with 1 chunks...\n",
      "Processing Section: 152 of 185 with 4 chunks...\n",
      "Processing Section: 153 of 185 with 3 chunks...\n",
      "Processing Section: 154 of 185 with 1 chunks...\n",
      "Processing Section: 155 of 185 with 2 chunks...\n",
      "Processing Section: 156 of 185 with 1 chunks...\n",
      "Processing Section: 157 of 185 with 1 chunks...\n",
      "Processing Section: 158 of 185 with 1 chunks...\n",
      "Processing Section: 159 of 185 with 1 chunks...\n",
      "Processing Section: 160 of 185 with 2 chunks...\n",
      "Processing Section: 161 of 185 with 1 chunks...\n",
      "Processing Section: 162 of 185 with 2 chunks...\n",
      "Processing Section: 163 of 185 with 1 chunks...\n",
      "Processing Section: 164 of 185 with 1 chunks...\n",
      "Processing Section: 165 of 185 with 1 chunks...\n",
      "Processing Section: 166 of 185 with 1 chunks...\n",
      "Processing Section: 167 of 185 with 1 chunks...\n",
      "Processing Section: 168 of 185 with 1 chunks...\n",
      "Processing Section: 169 of 185 with 1 chunks...\n",
      "Processing Section: 170 of 185 with 1 chunks...\n",
      "Processing Section: 171 of 185 with 1 chunks...\n",
      "Processing Section: 172 of 185 with 1 chunks...\n",
      "Processing Section: 173 of 185 with 3 chunks...\n",
      "Processing Section: 174 of 185 with 1 chunks...\n",
      "Processing Section: 175 of 185 with 1 chunks...\n",
      "Processing Section: 176 of 185 with 1 chunks...\n",
      "Processing Section: 177 of 185 with 2 chunks...\n",
      "Processing Section: 178 of 185 with 1 chunks...\n",
      "Processing Section: 179 of 185 with 1 chunks...\n",
      "Processing Section: 180 of 185 with 1 chunks...\n",
      "Processing Section: 181 of 185 with 1 chunks...\n",
      "Processing Section: 182 of 185 with 1 chunks...\n",
      "Processing Section: 183 of 185 with 1 chunks...\n",
      "Processing Section: 184 of 185 with 2 chunks...\n",
      "Processing Section: 185 of 185 with 2 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/msft-2022_Shareholder_Letter.docx.pkl\n",
      "Processing Section: 1 of 16 with 2 chunks...\n",
      "Processing Section: 2 of 16 with 1 chunks...\n",
      "Processing Section: 3 of 16 with 1 chunks...\n",
      "Processing Section: 4 of 16 with 2 chunks...\n",
      "Processing Section: 5 of 16 with 2 chunks...\n",
      "Processing Section: 6 of 16 with 1 chunks...\n",
      "Processing Section: 7 of 16 with 1 chunks...\n",
      "Processing Section: 8 of 16 with 1 chunks...\n",
      "Processing Section: 9 of 16 with 1 chunks...\n",
      "Processing Section: 10 of 16 with 1 chunks...\n",
      "Processing Section: 11 of 16 with 1 chunks...\n",
      "Processing Section: 12 of 16 with 1 chunks...\n",
      "Processing Section: 13 of 16 with 1 chunks...\n",
      "Processing Section: 14 of 16 with 1 chunks...\n",
      "Processing Section: 15 of 16 with 1 chunks...\n",
      "Processing Section: 16 of 16 with 2 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/MSFT_FY22Q4_10K.docx.pkl\n",
      "Processing Section: 1 of 191 with 1 chunks...\n",
      "Processing Section: 2 of 191 with 4 chunks...\n",
      "Processing Section: 3 of 191 with 1 chunks...\n",
      "Processing Section: 4 of 191 with 1 chunks...\n",
      "Processing Section: 5 of 191 with 1 chunks...\n",
      "Processing Section: 6 of 191 with 1 chunks...\n",
      "Processing Section: 7 of 191 with 2 chunks...\n",
      "Processing Section: 8 of 191 with 3 chunks...\n",
      "Processing Section: 9 of 191 with 3 chunks...\n",
      "Processing Section: 10 of 191 with 1 chunks...\n",
      "Processing Section: 11 of 191 with 1 chunks...\n",
      "Processing Section: 12 of 191 with 1 chunks...\n",
      "Processing Section: 13 of 191 with 1 chunks...\n",
      "Processing Section: 14 of 191 with 1 chunks...\n",
      "Processing Section: 15 of 191 with 1 chunks...\n",
      "Processing Section: 16 of 191 with 1 chunks...\n",
      "Processing Section: 17 of 191 with 2 chunks...\n",
      "Processing Section: 18 of 191 with 1 chunks...\n",
      "Processing Section: 19 of 191 with 1 chunks...\n",
      "Processing Section: 20 of 191 with 1 chunks...\n",
      "Processing Section: 21 of 191 with 1 chunks...\n",
      "Processing Section: 22 of 191 with 1 chunks...\n",
      "Processing Section: 23 of 191 with 1 chunks...\n",
      "Processing Section: 24 of 191 with 1 chunks...\n",
      "Processing Section: 25 of 191 with 1 chunks...\n",
      "Processing Section: 26 of 191 with 1 chunks...\n",
      "Processing Section: 27 of 191 with 2 chunks...\n",
      "Processing Section: 28 of 191 with 1 chunks...\n",
      "Processing Section: 29 of 191 with 1 chunks...\n",
      "Processing Section: 30 of 191 with 1 chunks...\n",
      "Processing Section: 31 of 191 with 1 chunks...\n",
      "Processing Section: 32 of 191 with 1 chunks...\n",
      "Processing Section: 33 of 191 with 1 chunks...\n",
      "Processing Section: 34 of 191 with 1 chunks...\n",
      "Processing Section: 35 of 191 with 3 chunks...\n",
      "Processing Section: 36 of 191 with 1 chunks...\n",
      "Processing Section: 37 of 191 with 1 chunks...\n",
      "Processing Section: 38 of 191 with 1 chunks...\n",
      "Processing Section: 39 of 191 with 1 chunks...\n",
      "Processing Section: 40 of 191 with 1 chunks...\n",
      "Processing Section: 41 of 191 with 1 chunks...\n",
      "Processing Section: 42 of 191 with 1 chunks...\n",
      "Processing Section: 43 of 191 with 1 chunks...\n",
      "Processing Section: 44 of 191 with 1 chunks...\n",
      "Processing Section: 45 of 191 with 1 chunks...\n",
      "Processing Section: 46 of 191 with 1 chunks...\n",
      "Processing Section: 47 of 191 with 3 chunks...\n",
      "Processing Section: 48 of 191 with 1 chunks...\n",
      "Processing Section: 49 of 191 with 1 chunks...\n",
      "Processing Section: 50 of 191 with 1 chunks...\n",
      "Processing Section: 51 of 191 with 1 chunks...\n",
      "Processing Section: 52 of 191 with 2 chunks...\n",
      "Processing Section: 53 of 191 with 2 chunks...\n",
      "Processing Section: 54 of 191 with 2 chunks...\n",
      "Processing Section: 55 of 191 with 2 chunks...\n",
      "Processing Section: 56 of 191 with 2 chunks...\n",
      "Processing Section: 57 of 191 with 3 chunks...\n",
      "Processing Section: 58 of 191 with 1 chunks...\n",
      "Processing Section: 59 of 191 with 2 chunks...\n",
      "Processing Section: 60 of 191 with 2 chunks...\n",
      "Processing Section: 61 of 191 with 8 chunks...\n",
      "Processing Section: 62 of 191 with 2 chunks...\n",
      "Processing Section: 63 of 191 with 5 chunks...\n",
      "Processing Section: 64 of 191 with 1 chunks...\n",
      "Processing Section: 65 of 191 with 1 chunks...\n",
      "Processing Section: 66 of 191 with 1 chunks...\n",
      "Processing Section: 67 of 191 with 1 chunks...\n",
      "Processing Section: 68 of 191 with 1 chunks...\n",
      "Processing Section: 69 of 191 with 2 chunks...\n",
      "Processing Section: 70 of 191 with 2 chunks...\n",
      "Processing Section: 71 of 191 with 1 chunks...\n",
      "Processing Section: 72 of 191 with 1 chunks...\n",
      "Processing Section: 73 of 191 with 1 chunks...\n",
      "Processing Section: 74 of 191 with 1 chunks...\n",
      "Processing Section: 75 of 191 with 1 chunks...\n",
      "Processing Section: 76 of 191 with 1 chunks...\n",
      "Processing Section: 77 of 191 with 2 chunks...\n",
      "Processing Section: 78 of 191 with 2 chunks...\n",
      "Processing Section: 79 of 191 with 2 chunks...\n",
      "Processing Section: 80 of 191 with 1 chunks...\n",
      "Processing Section: 81 of 191 with 1 chunks...\n",
      "Processing Section: 82 of 191 with 1 chunks...\n",
      "Processing Section: 83 of 191 with 1 chunks...\n",
      "Processing Section: 84 of 191 with 2 chunks...\n",
      "Processing Section: 85 of 191 with 1 chunks...\n",
      "Processing Section: 86 of 191 with 2 chunks...\n",
      "Processing Section: 87 of 191 with 1 chunks...\n",
      "Processing Section: 88 of 191 with 1 chunks...\n",
      "Processing Section: 89 of 191 with 1 chunks...\n",
      "Processing Section: 90 of 191 with 1 chunks...\n",
      "Processing Section: 91 of 191 with 1 chunks...\n",
      "Processing Section: 92 of 191 with 1 chunks...\n",
      "Processing Section: 93 of 191 with 1 chunks...\n",
      "Processing Section: 94 of 191 with 1 chunks...\n",
      "Processing Section: 95 of 191 with 1 chunks...\n",
      "Processing Section: 96 of 191 with 1 chunks...\n",
      "Processing Section: 97 of 191 with 1 chunks...\n",
      "Processing Section: 98 of 191 with 1 chunks...\n",
      "Processing Section: 99 of 191 with 1 chunks...\n",
      "Processing Section: 100 of 191 with 1 chunks...\n",
      "Processing Section: 101 of 191 with 1 chunks...\n",
      "Processing Section: 102 of 191 with 1 chunks...\n",
      "Processing Section: 103 of 191 with 1 chunks...\n",
      "Processing Section: 104 of 191 with 1 chunks...\n",
      "Processing Section: 105 of 191 with 1 chunks...\n",
      "Processing Section: 106 of 191 with 2 chunks...\n",
      "Processing Section: 107 of 191 with 1 chunks...\n",
      "Processing Section: 108 of 191 with 1 chunks...\n",
      "Processing Section: 109 of 191 with 1 chunks...\n",
      "Processing Section: 110 of 191 with 1 chunks...\n",
      "Processing Section: 111 of 191 with 1 chunks...\n",
      "Processing Section: 112 of 191 with 6 chunks...\n",
      "Processing Section: 113 of 191 with 1 chunks...\n",
      "Processing Section: 114 of 191 with 1 chunks...\n",
      "Processing Section: 115 of 191 with 1 chunks...\n",
      "Processing Section: 116 of 191 with 1 chunks...\n",
      "Processing Section: 117 of 191 with 1 chunks...\n",
      "Processing Section: 118 of 191 with 1 chunks...\n",
      "Processing Section: 119 of 191 with 1 chunks...\n",
      "Processing Section: 120 of 191 with 5 chunks...\n",
      "Processing Section: 121 of 191 with 1 chunks...\n",
      "Processing Section: 122 of 191 with 1 chunks...\n",
      "Processing Section: 123 of 191 with 1 chunks...\n",
      "Processing Section: 124 of 191 with 1 chunks...\n",
      "Processing Section: 125 of 191 with 1 chunks...\n",
      "Processing Section: 126 of 191 with 1 chunks...\n",
      "Processing Section: 127 of 191 with 1 chunks...\n",
      "Processing Section: 128 of 191 with 1 chunks...\n",
      "Processing Section: 129 of 191 with 2 chunks...\n",
      "Processing Section: 130 of 191 with 1 chunks...\n",
      "Processing Section: 131 of 191 with 1 chunks...\n",
      "Processing Section: 132 of 191 with 1 chunks...\n",
      "Processing Section: 133 of 191 with 1 chunks...\n",
      "Processing Section: 134 of 191 with 1 chunks...\n",
      "Processing Section: 135 of 191 with 1 chunks...\n",
      "Processing Section: 136 of 191 with 1 chunks...\n",
      "Processing Section: 137 of 191 with 2 chunks...\n",
      "Processing Section: 138 of 191 with 3 chunks...\n",
      "Processing Section: 139 of 191 with 1 chunks...\n",
      "Processing Section: 140 of 191 with 2 chunks...\n",
      "Processing Section: 141 of 191 with 1 chunks...\n",
      "Processing Section: 142 of 191 with 1 chunks...\n",
      "Processing Section: 143 of 191 with 1 chunks...\n",
      "Processing Section: 144 of 191 with 1 chunks...\n",
      "Processing Section: 145 of 191 with 1 chunks...\n",
      "Processing Section: 146 of 191 with 1 chunks...\n",
      "Processing Section: 147 of 191 with 1 chunks...\n",
      "Processing Section: 148 of 191 with 2 chunks...\n",
      "Processing Section: 149 of 191 with 1 chunks...\n",
      "Processing Section: 150 of 191 with 1 chunks...\n",
      "Processing Section: 151 of 191 with 1 chunks...\n",
      "Processing Section: 152 of 191 with 1 chunks...\n",
      "Processing Section: 153 of 191 with 1 chunks...\n",
      "Processing Section: 154 of 191 with 1 chunks...\n",
      "Processing Section: 155 of 191 with 5 chunks...\n",
      "Processing Section: 156 of 191 with 4 chunks...\n",
      "Processing Section: 157 of 191 with 3 chunks...\n",
      "Processing Section: 158 of 191 with 3 chunks...\n",
      "Processing Section: 159 of 191 with 1 chunks...\n",
      "Processing Section: 160 of 191 with 1 chunks...\n",
      "Processing Section: 161 of 191 with 1 chunks...\n",
      "Processing Section: 162 of 191 with 1 chunks...\n",
      "Processing Section: 163 of 191 with 1 chunks...\n",
      "Processing Section: 164 of 191 with 2 chunks...\n",
      "Processing Section: 165 of 191 with 3 chunks...\n",
      "Processing Section: 166 of 191 with 1 chunks...\n",
      "Processing Section: 167 of 191 with 1 chunks...\n",
      "Processing Section: 168 of 191 with 1 chunks...\n",
      "Processing Section: 169 of 191 with 1 chunks...\n",
      "Processing Section: 170 of 191 with 1 chunks...\n",
      "Processing Section: 171 of 191 with 1 chunks...\n",
      "Processing Section: 172 of 191 with 1 chunks...\n",
      "Processing Section: 173 of 191 with 1 chunks...\n",
      "Processing Section: 174 of 191 with 4 chunks...\n",
      "Processing Section: 175 of 191 with 1 chunks...\n",
      "Processing Section: 176 of 191 with 1 chunks...\n",
      "Processing Section: 177 of 191 with 1 chunks...\n",
      "Processing Section: 178 of 191 with 2 chunks...\n",
      "Processing Section: 179 of 191 with 2 chunks...\n",
      "Processing Section: 180 of 191 with 1 chunks...\n",
      "Processing Section: 181 of 191 with 1 chunks...\n",
      "Processing Section: 182 of 191 with 1 chunks...\n",
      "Processing Section: 183 of 191 with 2 chunks...\n",
      "Processing Section: 184 of 191 with 1 chunks...\n",
      "Processing Section: 185 of 191 with 1 chunks...\n",
      "Processing Section: 186 of 191 with 1 chunks...\n",
      "Processing Section: 187 of 191 with 1 chunks...\n",
      "Processing Section: 188 of 191 with 1 chunks...\n",
      "Processing Section: 189 of 191 with 1 chunks...\n",
      "Processing Section: 190 of 191 with 1 chunks...\n",
      "Processing Section: 191 of 191 with 14 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/nvda-Q3FY24-CFO-Commentary.pdf.pkl\n",
      "Processing Section: 1 of 5 with 2 chunks...\n",
      "Processing Section: 2 of 5 with 2 chunks...\n",
      "Processing Section: 3 of 5 with 3 chunks...\n",
      "Processing Section: 4 of 5 with 2 chunks...\n",
      "Processing Section: 5 of 5 with 4 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/NVIDIA-10Q.pdf.pkl\n",
      "Processing Section: 1 of 50 with 3 chunks...\n",
      "Processing Section: 2 of 50 with 1 chunks...\n",
      "Processing Section: 3 of 50 with 9 chunks...\n",
      "Processing Section: 4 of 50 with 2 chunks...\n",
      "Processing Section: 5 of 50 with 1 chunks...\n",
      "Processing Section: 6 of 50 with 2 chunks...\n",
      "Processing Section: 7 of 50 with 1 chunks...\n",
      "Processing Section: 8 of 50 with 1 chunks...\n",
      "Processing Section: 9 of 50 with 5 chunks...\n",
      "Processing Section: 10 of 50 with 2 chunks...\n",
      "Processing Section: 11 of 50 with 3 chunks...\n",
      "Processing Section: 12 of 50 with 1 chunks...\n",
      "Processing Section: 13 of 50 with 3 chunks...\n",
      "Processing Section: 14 of 50 with 1 chunks...\n",
      "Processing Section: 15 of 50 with 1 chunks...\n",
      "Processing Section: 16 of 50 with 1 chunks...\n",
      "Processing Section: 17 of 50 with 3 chunks...\n",
      "Processing Section: 18 of 50 with 1 chunks...\n",
      "Processing Section: 19 of 50 with 5 chunks...\n",
      "Processing Section: 20 of 50 with 1 chunks...\n",
      "Processing Section: 21 of 50 with 1 chunks...\n",
      "Processing Section: 22 of 50 with 2 chunks...\n",
      "Processing Section: 23 of 50 with 2 chunks...\n",
      "Processing Section: 24 of 50 with 1 chunks...\n",
      "Processing Section: 25 of 50 with 3 chunks...\n",
      "Processing Section: 26 of 50 with 1 chunks...\n",
      "Processing Section: 27 of 50 with 1 chunks...\n",
      "Processing Section: 28 of 50 with 1 chunks...\n",
      "Processing Section: 29 of 50 with 1 chunks...\n",
      "Processing Section: 30 of 50 with 1 chunks...\n",
      "Processing Section: 31 of 50 with 3 chunks...\n",
      "Processing Section: 32 of 50 with 1 chunks...\n",
      "Processing Section: 33 of 50 with 2 chunks...\n",
      "Processing Section: 34 of 50 with 2 chunks...\n",
      "Processing Section: 35 of 50 with 1 chunks...\n",
      "Processing Section: 36 of 50 with 1 chunks...\n",
      "Processing Section: 37 of 50 with 1 chunks...\n",
      "Processing Section: 38 of 50 with 1 chunks...\n",
      "Processing Section: 39 of 50 with 1 chunks...\n",
      "Processing Section: 40 of 50 with 1 chunks...\n",
      "Processing Section: 41 of 50 with 1 chunks...\n",
      "Processing Section: 42 of 50 with 1 chunks...\n",
      "Processing Section: 43 of 50 with 1 chunks...\n",
      "Processing Section: 44 of 50 with 1 chunks...\n",
      "Processing Section: 45 of 50 with 20 chunks...\n",
      "Processing Section: 46 of 50 with 2 chunks...\n",
      "Processing Section: 47 of 50 with 1 chunks...\n",
      "Processing Section: 48 of 50 with 1 chunks...\n",
      "Processing Section: 49 of 50 with 5 chunks...\n",
      "Processing Section: 50 of 50 with 2 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/orcl-2q24-pressrelease-December-final.pdf.pkl\n",
      "Processing Section: 1 of 5 with 1 chunks...\n",
      "Processing Section: 2 of 5 with 2 chunks...\n",
      "Processing Section: 3 of 5 with 1 chunks...\n",
      "Processing Section: 4 of 5 with 1 chunks...\n",
      "Processing Section: 5 of 5 with 21 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/orcl-f20d8dea-697e-464e-b775-b0e33d1db211.pdf.pkl\n",
      "Processing Section: 1 of 49 with 1 chunks...\n",
      "Processing Section: 2 of 49 with 1 chunks...\n",
      "Processing Section: 3 of 49 with 11 chunks...\n",
      "Processing Section: 4 of 49 with 1 chunks...\n",
      "Processing Section: 5 of 49 with 1 chunks...\n",
      "Processing Section: 6 of 49 with 1 chunks...\n",
      "Processing Section: 7 of 49 with 1 chunks...\n",
      "Processing Section: 8 of 49 with 1 chunks...\n",
      "Processing Section: 9 of 49 with 1 chunks...\n",
      "Processing Section: 10 of 49 with 1 chunks...\n",
      "Processing Section: 11 of 49 with 1 chunks...\n",
      "Processing Section: 12 of 49 with 1 chunks...\n",
      "Processing Section: 13 of 49 with 2 chunks...\n",
      "Processing Section: 14 of 49 with 2 chunks...\n",
      "Processing Section: 15 of 49 with 1 chunks...\n",
      "Processing Section: 16 of 49 with 1 chunks...\n",
      "Processing Section: 17 of 49 with 1 chunks...\n",
      "Processing Section: 18 of 49 with 1 chunks...\n",
      "Processing Section: 19 of 49 with 1 chunks...\n",
      "Processing Section: 20 of 49 with 1 chunks...\n",
      "Processing Section: 21 of 49 with 2 chunks...\n",
      "Processing Section: 22 of 49 with 4 chunks...\n",
      "Processing Section: 23 of 49 with 1 chunks...\n",
      "Processing Section: 24 of 49 with 1 chunks...\n",
      "Processing Section: 25 of 49 with 2 chunks...\n",
      "Processing Section: 26 of 49 with 1 chunks...\n",
      "Processing Section: 27 of 49 with 1 chunks...\n",
      "Processing Section: 28 of 49 with 3 chunks...\n",
      "Processing Section: 29 of 49 with 2 chunks...\n",
      "Processing Section: 30 of 49 with 1 chunks...\n",
      "Processing Section: 31 of 49 with 1 chunks...\n",
      "Processing Section: 32 of 49 with 1 chunks...\n",
      "Processing Section: 33 of 49 with 1 chunks...\n",
      "Processing Section: 34 of 49 with 1 chunks...\n",
      "Processing Section: 35 of 49 with 2 chunks...\n",
      "Processing Section: 36 of 49 with 2 chunks...\n",
      "Processing Section: 37 of 49 with 1 chunks...\n",
      "Processing Section: 38 of 49 with 3 chunks...\n",
      "Processing Section: 39 of 49 with 3 chunks...\n",
      "Processing Section: 40 of 49 with 5 chunks...\n",
      "Processing Section: 41 of 49 with 3 chunks...\n",
      "Processing Section: 42 of 49 with 4 chunks...\n",
      "Processing Section: 43 of 49 with 1 chunks...\n",
      "Processing Section: 44 of 49 with 2 chunks...\n",
      "Processing Section: 45 of 49 with 1 chunks...\n",
      "Processing Section: 46 of 49 with 2 chunks...\n",
      "Processing Section: 47 of 49 with 1 chunks...\n",
      "Processing Section: 48 of 49 with 1 chunks...\n",
      "Processing Section: 49 of 49 with 3 chunks...\n",
      "/aci/data/data/customers/financial-docs/pkl/orcl-Q224_Form8K_Exhibit99-1_Earnings_Release_Tables_Final.pdf.pkl\n",
      "Processing Section: 1 of 1 with 21 chunks...\n"
     ]
    }
   ],
   "source": [
    "# Process the Pickle files which contain the results of the Document Intelligence Analyze Results\n",
    "# We will use the markdown text within this for chunking, etc\n",
    "# The output will be a set of JSON files which be uploaaded to Azure AI Search in the next step\n",
    "# These JSON files can be saved for BCDR purposes so that you do not need to reprocess the original content\n",
    "for pkl_file in pkl_files:\n",
    "    print (pkl_file)\n",
    "    \n",
    "    json_data_base = {}\n",
    "    base_file = os.path.basename(pkl_file)\n",
    "    base_file=base_file[:base_file.rfind('.pkl')]\n",
    "    json_out_file = os.path.join(json_dir, base_file + \".json\")\n",
    "\n",
    "    if os.path.exists(json_out_file) == False:\n",
    "        json_data_base[\"parent_id\"] = base64_encode_string(os.path.basename(pkl_file)[:pkl_file.rfind('.pkl')])\n",
    "        # json_data_base[\"url\"] = download_url\n",
    "        json_data_base[\"file_name\"] = os.path.basename(pkl_file)[:pkl_file.rfind('.pkl')]\n",
    "        json_data_base[\"last_updated\"] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'\n",
    "    \n",
    "        with open(pkl_file, 'rb') as pkl_in:\n",
    "            analyze_result = pickle.load(pkl_in)\n",
    "        content = analyze_result['content']\n",
    "    \n",
    "        md_header_splits = markdown_splitter.split_text(content)\n",
    "        documents = []\n",
    "        section_counter = 0\n",
    "        total_sections = len(md_header_splits)\n",
    "        chunk_id = 0\n",
    "        for s in md_header_splits:\n",
    "            section_counter+=1\n",
    "    \n",
    "            section_content = s.page_content\n",
    "            chunks = text_splitter.split_text(section_content)\n",
    "            print ('Processing Section:', section_counter, 'of', total_sections, 'with', len(chunks), 'chunks...')\n",
    "    \n",
    "            if chunks != []:\n",
    "                for chunk in chunks:\n",
    "                    json_data = json_data_base \n",
    "                    json_data = copy.deepcopy(json_data_base)  \n",
    "                    json_data[\"chunk_id\"] = str(chunk_id)\n",
    "                    json_data[\"chunk\"] = chunk\n",
    "                    json_data[\"title\"] = generate_title(json_data['chunk'])\n",
    "                    chunk_content = \"File Name: \" + base_file + \"\\n\"\n",
    "                    chunk_content += \"Section Title: \" + json_data[\"title\"] + \"\\n\"\n",
    "                    chunk_content += chunk\n",
    "                    json_data[\"vector\"] = generate_embeddings(chunk_content)\n",
    "                    chunk_id+=1\n",
    "                    documents.append(json_data)\n",
    "            else:\n",
    "                print ('No content found for this file')\n",
    "    \n",
    "        with open(json_out_file, \"w\") as j_out:\n",
    "            j_out.write(json.dumps(documents))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e945379-6d7f-48b6-b3f0-13f3c1509c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_default",
   "language": "python",
   "name": "py39_default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
